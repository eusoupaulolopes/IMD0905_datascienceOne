{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lesson #17 - Data Cleaning Walkthrough_ combining the data.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Oi0OXsx48yFX","colab_type":"text"},"cell_type":"markdown","source":["# 1.0 Data Cleaning Walkthrough: Combining the Data"]},{"metadata":{"id":"OobotGnV9Ws_","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":276},"outputId":"30a5b8c6-02ca-42fe-9525-562be619ff84","executionInfo":{"status":"ok","timestamp":1544459635606,"user_tz":120,"elapsed":135688,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3a28a130-988b-4e71-b5ea-5fa419ac2cf7\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-3a28a130-988b-4e71-b5ea-5fa419ac2cf7\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving ap_2010.csv to ap_2010.csv\n","Saving class_size.csv to class_size.csv\n","Saving demographics.csv to demographics.csv\n","Saving graduation.csv to graduation.csv\n","Saving hs_directory.csv to hs_directory.csv\n","Saving sat_results.csv to sat_results.csv\n","Saving survey.csv to survey.csv\n"],"name":"stdout"}]},{"metadata":{"id":"8g6qIPm89iwg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"4c41eae3-6d40-4ee5-c18d-18cc218705a4","executionInfo":{"status":"ok","timestamp":1544475442615,"user_tz":120,"elapsed":1157,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["# put your code here\n","\n","import pandas as pd\n","data_files = [\n","    \"ap_2010.csv\",\n","    \"class_size.csv\",\n","    \"demographics.csv\",\n","    \"graduation.csv\",\n","    \"hs_directory.csv\",\n","    \"sat_results.csv\",\n","    'survey.csv'\n","]\n","data = {}\n","\n","for file in data_files:\n","  dataset = pd.read_csv(file)\n","  k = file.replace(\".csv\", \"\")\n","  data[k] = dataset\n","  print(dataset.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["(258, 6)\n","(27611, 19)\n","(10075, 39)\n","(25096, 24)\n","(435, 68)\n","(478, 8)\n","(1702, 24)\n"],"name":"stdout"}]},{"metadata":{"id":"H2CF1nWo8yFZ","colab_type":"text"},"cell_type":"markdown","source":["## 1.1 Introduction"]},{"metadata":{"id":"Z2x3NcmX8yFa","colab_type":"text"},"cell_type":"markdown","source":["In the last mission, we began investigating possible relationships between **SAT scores** and **demographic factors**. In order to do this, we acquired several data sets about [New York City public schools](https://data.cityofnewyork.us/data?cat=education). We manipulated these data sets, and found that we could combine them all using the **DBN** column. All of the data sets are currently stored as **keys** in the **data** dictionary. Each individual data set is a pandas dataframe.\n","\n","In this section, **we'll clean the data a bit more**, then **combine** it. Finally, we'll **compute correlations** and perform some analysis.\n","\n","The first thing we'll need to do in preparation for the merge is condense some of the data sets. In the last section, we noticed that the values in the **DBN** column were unique in the **sat_results** data set. Other data sets like **class_size** had duplicate **DBN** values, however.\n","\n","We'll need to condense these data sets so that each value in the **DBN** column is unique. If not, we'll run into issues when it comes time to combine the data sets.\n","\n","While the main data set we want to analyze, **sat_results**, has unique **DBN** values for every high school in New York City, other data sets aren't as clean. A single row in the **sat_results** data set may match multiple rows in the **class_size** data set, for example. This situation will create problems, because we don't know which of the multiple entries in the **class_size** data set we should combine with the single matching entry in **sat_results**. Here's a diagram that illustrates the problem:\n","\n","\n","<left><img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1deYm5RdQXO2xMX6dUgHLvqDEWipk3axq\"></left>\n","\n","In the diagram above, we can't just combine the rows from both data sets because there are several cases where multiple rows in **class_size** match a single row in **sat_results.**\n","\n","To resolve this issue, we'll condense the **class_size**, **graduation**, and **demographics** data sets so that each **DBN** is unique."]},{"metadata":{"id":"L46dQU968yFb","colab_type":"text"},"cell_type":"markdown","source":["## 1.2 Condensing the Class Size Data Set"]},{"metadata":{"id":"yRCu0U0-8yFc","colab_type":"text"},"cell_type":"markdown","source":["The first data set that we'll condense is **class_size**. The first few rows of **class_size** look like this:\n","\n","|__| CSD | BOROUGH | SCHOOL CODE | SCHOOL NAME               | GRADE | PROGRAM TYPE | CORE SUBJECT (MS CORE and 9-12 ONLY) | CORE COURSE (MS CORE and 9-12 ONLY) | SERVICE CATEGORY(K-9* ONLY) | NUMBER OF STUDENTS / SEATS FILLED | NUMBER OF SECTIONS |\n","|---|-----|---------|-------------|---------------------------|-------|--------------|--------------------------------------|-------------------------------------|-----------------------------|-----------------------------------|--------------------|\n","| 0 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | GEN ED       | -                                    | -                                   | -                           | 19.0                              | 1.0                |\n","| 1 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | CTT          | -                                    | -                                   | -                           | 21.0                              | 1.0                |\n","| 2 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | GEN ED       | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 3 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | CTT          | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 4 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 02    | GEN ED       | -                                    | -                                   | -                           | 15.0                              | 1.0                |\n","\n","As you can see, the first few rows all pertain to the same school, which is why the **DBN** appears more than once. It looks like each school has multiple values for **GRADE**, **PROGRAM TYPE**, **CORE SUBJECT (MS CORE and 9-12 ONLY)**, and **CORE COURSE (MS CORE and 9-12 ONLY)**.\n","\n","If we look at the unique values for **GRADE**, we get the following:\n","\n","```python\n","array(['0K', '01', '02', '03', '04', '05', '0K-09', nan, '06', '07', '08',\n","       'MS Core', '09-12', '09'], dtype=object)\n","```\n","\n","Because we're dealing with high schools, we're only concerned with grades 9 through 12. That means we only want to pick rows where the value in the **GRADE** column is **09-12**.\n","\n","If we look at the unique values for **PROGRAM TYPE**, we get the following:\n","\n","```python\n","array(['GEN ED', 'CTT', 'SPEC ED', nan, 'G&T'], dtype=object)\n","```\n","\n","Each school can have multiple program types. Because **GEN ED** is the largest category by far, let's only select rows where **PROGRAM TYPE** is **GEN ED**.\n","\n"]},{"metadata":{"id":"gL1mmbAK8yFc","colab_type":"text"},"cell_type":"markdown","source":["## 1.3 Condensing the Class Size Data Set"]},{"metadata":{"id":"8Zqa50Z08yFd","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","- Create a new variable called **class_size**, and assign the value of **data[\"class_size\"]** to it.\n","- Filter **class_size** so the **GRADE** column only contains the value **09-12.** Note that the name of the **GRADE** column has a space at the end; you'll generate an error if you don't include it.\n","- Filter **lass_size** so that the **PROGRAM TYPE** column only contains the value **GEN ED.**\n","- Display the first five rows of **class_size** to verify."]},{"metadata":{"id":"8S8Ho7Tz8yFd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"098cf110-8687-488b-cd80-093faf466e08","executionInfo":{"status":"ok","timestamp":1544475448585,"user_tz":120,"elapsed":714,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["# put your code here\n","class_size = data['class_size']\n","class_size = class_size[class_size['GRADE '] == '09-12']\n","class_size = class_size[class_size['PROGRAM TYPE'] == 'GEN ED']\n","class_size.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>CSD</th>\n","      <th>BOROUGH</th>\n","      <th>SCHOOL CODE</th>\n","      <th>SCHOOL NAME</th>\n","      <th>GRADE</th>\n","      <th>PROGRAM TYPE</th>\n","      <th>CORE SUBJECT (MS CORE and 9-12 ONLY)</th>\n","      <th>CORE COURSE (MS CORE and 9-12 ONLY)</th>\n","      <th>SERVICE CATEGORY(K-9* ONLY)</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>DATA SOURCE</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","      <th>padded_csd</th>\n","      <th>DBN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>225</th>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 9</td>\n","      <td>-</td>\n","      <td>63.0</td>\n","      <td>3.0</td>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>25.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>226</th>\n","      <td>226</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 10</td>\n","      <td>-</td>\n","      <td>79.0</td>\n","      <td>3.0</td>\n","      <td>26.3</td>\n","      <td>24.0</td>\n","      <td>31.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>227</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 11</td>\n","      <td>-</td>\n","      <td>38.0</td>\n","      <td>2.0</td>\n","      <td>19.0</td>\n","      <td>16.0</td>\n","      <td>22.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>228</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 12</td>\n","      <td>-</td>\n","      <td>69.0</td>\n","      <td>3.0</td>\n","      <td>23.0</td>\n","      <td>13.0</td>\n","      <td>30.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>229</th>\n","      <td>229</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>MATH</td>\n","      <td>Integrated Algebra</td>\n","      <td>-</td>\n","      <td>53.0</td>\n","      <td>3.0</td>\n","      <td>17.7</td>\n","      <td>16.0</td>\n","      <td>21.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>01M292</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Unnamed: 0  CSD BOROUGH SCHOOL CODE  \\\n","225         225    1       M        M292   \n","226         226    1       M        M292   \n","227         227    1       M        M292   \n","228         228    1       M        M292   \n","229         229    1       M        M292   \n","\n","                                       SCHOOL NAME GRADE  PROGRAM TYPE  \\\n","225  Henry Street School for International Studies  09-12       GEN ED   \n","226  Henry Street School for International Studies  09-12       GEN ED   \n","227  Henry Street School for International Studies  09-12       GEN ED   \n","228  Henry Street School for International Studies  09-12       GEN ED   \n","229  Henry Street School for International Studies  09-12       GEN ED   \n","\n","    CORE SUBJECT (MS CORE and 9-12 ONLY) CORE COURSE (MS CORE and 9-12 ONLY)  \\\n","225                              ENGLISH                           English 9   \n","226                              ENGLISH                          English 10   \n","227                              ENGLISH                          English 11   \n","228                              ENGLISH                          English 12   \n","229                                 MATH                  Integrated Algebra   \n","\n","    SERVICE CATEGORY(K-9* ONLY)  NUMBER OF STUDENTS / SEATS FILLED  \\\n","225                           -                               63.0   \n","226                           -                               79.0   \n","227                           -                               38.0   \n","228                           -                               69.0   \n","229                           -                               53.0   \n","\n","     NUMBER OF SECTIONS  AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  \\\n","225                 3.0                21.0                    19.0   \n","226                 3.0                26.3                    24.0   \n","227                 2.0                19.0                    16.0   \n","228                 3.0                23.0                    13.0   \n","229                 3.0                17.7                    16.0   \n","\n","     SIZE OF LARGEST CLASS DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO  \\\n","225                   25.0       STARS                             NaN   \n","226                   31.0       STARS                             NaN   \n","227                   22.0       STARS                             NaN   \n","228                   30.0       STARS                             NaN   \n","229                   21.0       STARS                             NaN   \n","\n","     padded_csd     DBN  \n","225           1  01M292  \n","226           1  01M292  \n","227           1  01M292  \n","228           1  01M292  \n","229           1  01M292  "]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"Th72ZVIj8yFf","colab_type":"text"},"cell_type":"markdown","source":["## 1.4 Computing Average Class Sizes"]},{"metadata":{"id":"00ydSvyt8yFg","colab_type":"text"},"cell_type":"markdown","source":["As we saw when we displayed **class_size** on the last screen, **DBN** still isn't completely unique. This is due to the **CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** columns.\n","\n","**CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** seem to pertain to different kinds of classes. For example, here are the unique values for **CORE SUBJECT (MS CORE and 9-12 ONLY)**:\n","\n","```python\n","array(['ENGLISH', 'MATH', 'SCIENCE', 'SOCIAL STUDIES'], dtype=object)\n","```\n","\n","This column only seems to include certain subjects. We want our class size data to include every single class a school offers -- not just a subset of them. What we can do is take the average across all of the classes a school offers. This will give us unique **DBN** values, while also incorporating as much data as possible into the average.\n","\n","Fortunately, we can use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to help us with this. The **DataFrame.groupby()** method will split a dataframe up into unique groups, based on a given column. We can then use the **agg()** method on the resulting **pandas.core.groupby** object to find the **mean** of each column.\n","\n","Let's say we have this data set:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1sJjENlTRR56RwYzBmmsU8aIMELgjx8zg\"></left>\n","\n","Using the **groupby()** method, we'll split this dataframe into four separate groups -- one with the **DBN 01M292**, one with the **DBN 01M332**, one with the **DBN 01M378**, and one with the **DBN 01M448**:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1y9imbMLKRDI50wQqPn7P6TAd6MfCL4Nq\"></left>\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1FitnyClxHDQLnoAB3jR7YI_jEPZZhkco\"></left>\n","\n","Then, we can compute the averages for the **AVERAGE CLASS SIZE** column in each of the four groups using the **agg()** method:\n","\n","<left><img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1gHVZixGOuGYYON_zU0OUPTJcC9Q_mKeV\"></left>\n","\n","After we group a dataframe and aggregate data based on it, the column we performed the grouping on (in this case **DBN**) will become the index, and will no longer appear as a column in the data itself. To undo this change and keep **DBN** as a column, we'll need to use [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html). This method will reset the index to a list of integers and make **DBN** a column again."]},{"metadata":{"id":"mMPOOzjN8yFg","colab_type":"text"},"cell_type":"markdown","source":["## 1.5 Computing Average Class Sizes"]},{"metadata":{"id":"sfdxxqf08yFh","colab_type":"text"},"cell_type":"markdown","source":["- Find the average values for each column associated with each **DBN** in **class_size**.\n","    - Use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to group **class_size** by **DBN**.\n","    - Use the [agg()](http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation) method on the resulting **pandas.core.groupby** object, along with the **numpy.mean()** function as an argument, to calculate the average of each group.\n","    - Assign the result back to **class_size**.\n","- Reset the index to make **DBN** a column again.\n","    - Use the [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html) method, along with the keyword argument **inplace=True**.\n","- Assign **class_size** back to the **class_size** key of the **data** dictionary.\n","- Display the first few rows of **data[\"class_size\"]** to verify that everything went okay."]},{"metadata":{"id":"xGKLTHOi8yFi","colab_type":"code","colab":{}},"cell_type":"code","source":["class_size = class_size.groupby('DBN').agg('mean')\n","#class_size = class_size.reset_index(inplace=True)\n","data['class_size'] = class_size\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cJ8o3vVcwnM_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"bf91909c-34c0-42ab-b4ca-303f06d14423","executionInfo":{"status":"ok","timestamp":1544475455448,"user_tz":120,"elapsed":700,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["data['class_size'].reset_index(inplace=True)\n","data['class_size'].head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>Unnamed: 0</th>\n","      <th>CSD</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","      <th>padded_csd</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>232.142857</td>\n","      <td>1.0</td>\n","      <td>88.0000</td>\n","      <td>4.000000</td>\n","      <td>22.564286</td>\n","      <td>18.50</td>\n","      <td>26.571429</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M332</td>\n","      <td>295.500000</td>\n","      <td>1.0</td>\n","      <td>46.0000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>21.00</td>\n","      <td>23.500000</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M378</td>\n","      <td>354.000000</td>\n","      <td>1.0</td>\n","      <td>33.0000</td>\n","      <td>1.000000</td>\n","      <td>33.000000</td>\n","      <td>33.00</td>\n","      <td>33.000000</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M448</td>\n","      <td>363.500000</td>\n","      <td>1.0</td>\n","      <td>105.6875</td>\n","      <td>4.750000</td>\n","      <td>22.231250</td>\n","      <td>18.25</td>\n","      <td>27.062500</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M450</td>\n","      <td>404.000000</td>\n","      <td>1.0</td>\n","      <td>57.6000</td>\n","      <td>2.733333</td>\n","      <td>21.200000</td>\n","      <td>19.40</td>\n","      <td>22.866667</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      DBN  Unnamed: 0  CSD  NUMBER OF STUDENTS / SEATS FILLED  \\\n","0  01M292  232.142857  1.0                            88.0000   \n","1  01M332  295.500000  1.0                            46.0000   \n","2  01M378  354.000000  1.0                            33.0000   \n","3  01M448  363.500000  1.0                           105.6875   \n","4  01M450  404.000000  1.0                            57.6000   \n","\n","   NUMBER OF SECTIONS  AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  \\\n","0            4.000000           22.564286                   18.50   \n","1            2.000000           22.000000                   21.00   \n","2            1.000000           33.000000                   33.00   \n","3            4.750000           22.231250                   18.25   \n","4            2.733333           21.200000                   19.40   \n","\n","   SIZE OF LARGEST CLASS  SCHOOLWIDE PUPIL-TEACHER RATIO  padded_csd  \n","0              26.571429                             NaN         1.0  \n","1              23.500000                             NaN         1.0  \n","2              33.000000                             NaN         1.0  \n","3              27.062500                             NaN         1.0  \n","4              22.866667                             NaN         1.0  "]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"W4XtGPNh8yFl","colab_type":"text"},"cell_type":"markdown","source":["## 1.6 Condensing the Demographics Data Set"]},{"metadata":{"id":"ijDhJZeb8yFl","colab_type":"text"},"cell_type":"markdown","source":["Now that we've finished condensing **class_size**, let's condense **demographics**. The first few rows look like this:\n","\n","| _| DBN    | Name                      | schoolyear | fl_percent | frl_percent | total_enrollment | prek | k  | grade1 | grade2 |\n","|---|--------|---------------------------|------------|------------|-------------|------------------|------|----|--------|--------|\n","| 0 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20052006   | 89.4       | NaN         | 281              | 15   | 36 | 40     | 33     |\n","| 1 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20062007   | 89.4       | NaN         | 243              | 15   | 29 | 39     | 38     |\n","| 2 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20072008   | 89.4       | NaN         | 261              | 18   | 43 | 39     | 36     |\n","| 3 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20082009   | 89.4       | NaN         | 252              | 17   | 37 | 44     | 32     |\n","| 4 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20092010   |  _          | 96.5        | 208              | 16   | 40 | 28     | 32     |\n","\n","In this case, the only column that prevents a given **DBN** from being unique is **schoolyear**. We only want to select rows where schoolyear is **20112012**. This will give us the most recent year of data, and also match our SAT results data."]},{"metadata":{"id":"VnDEAeuB8yFn","colab_type":"text"},"cell_type":"markdown","source":["## 1.7 Condensing the Demographics Data Set"]},{"metadata":{"id":"C5g2PiJt8yFn","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **demographics**, only selecting rows in **data[\"demographics\"]** where **schoolyear** is **20112012.**\n","    - **schoolyear** is actually an integer, so be careful about how you perform your comparison.\n","- Display the first few rows of **data[\"demographics\"]** to verify that the filtering worked."]},{"metadata":{"id":"4QUcmKI28yFo","colab_type":"code","colab":{}},"cell_type":"code","source":["  data['demographics'] = data[\"demographics\"][data[\"demographics\"]['schoolyear'] == 20112012]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x5dkSi8s8yFs","colab_type":"text"},"cell_type":"markdown","source":["## 1.8 Condensing the Graduation Data Set"]},{"metadata":{"id":"5xQzgi_Q8yFs","colab_type":"text"},"cell_type":"markdown","source":["Finally, we'll need to condense the **graduation** data set. Here are the first few rows:\n","\n","| _ | Demographic  | DBN    | School Name                           | Cohort   | Total Cohort | Total Grads - n |\n","|---|--------------|--------|---------------------------------------|----------|--------------|-----------------|\n","| 0 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2003     | 5            | s               |\n","| 1 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2004     | 55           | 37              |\n","| 2 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2005     | 64           | 43              |\n","| 3 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006     | 78           | 43              |\n","| 4 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006 Aug | 78           | 44              |\n","\n","The **Demographic** and **Cohort** columns are what prevent **DBN** from being unique in the **graduation** data. A **Cohort** appears to refer to the year the data represents, and the **Demographic** appears to refer to a specific demographic group. In this case, we want to pick data from the most recent Cohort available, which is 2006. We also want data from the full cohort, so we'll only pick rows where **Demographic** is **Total Cohort**."]},{"metadata":{"id":"IIHasD3G8yFt","colab_type":"text"},"cell_type":"markdown","source":["## 1.9 Condensing the Graduation Data Set"]},{"metadata":{"id":"7m8fZlxr8yFv","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **graduation**, only selecting rows where the **Cohort** column equals **2006.**\n","- Filter **graduation**, only selecting rows where the **Demographic** column equals **Total Cohort**.\n","- Display the first few rows of **data[\"graduation\"]** to verify that everything worked properly."]},{"metadata":{"id":"JjMUikQu8yFv","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here\n","\n","\n","data['graduation'] = data['graduation'][(data['graduation']['Cohort'] == '2006')& (data['graduation']['Demographic'] == \"Total Cohort\")]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ak0EfoSm8yFy","colab_type":"text"},"cell_type":"markdown","source":["## 1.10 Converting AP Test Scores"]},{"metadata":{"id":"DMmk__7t8yFy","colab_type":"text"},"cell_type":"markdown","source":["We're almost ready to combine all of the data sets. The only remaining thing to do is convert the [Advanced Placement (AP)](https://en.wikipedia.org/wiki/Advanced_Placement_exams) test scores from strings to numeric values. High school students take the AP exams before applying to college. There are several AP exams, each corresponding to a school subject. High school students who earn high scores may receive college credit.\n","\n","AP exams have a 1 to 5 scale; 3 or higher is a passing score. Many high school students take AP exams -- particularly those who attend academically challenging institutions. AP exams are much more rare in schools that lack funding or academic rigor.\n","\n","It will be interesting to find out whether AP exam scores are correlated with SAT scores across high schools. To determine this, we'll need to convert the AP exam scores in the **ap_2010** data set to numeric values first.\n","\n","There are three columns we'll need to convert:\n","\n","- **AP Test Takers** (note that there's a trailing space in the column name)\n","- **Total Exams Taken**\n","- **Number of Exams with scores 3 4 or 5**\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Convert each of the following columns in **ap_2010** to numeric values using the [pandas.to_numeric()](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.to_numeric.html) function with the keyword argument **errors=\"coerce\".**\n","    - **AP Test Takers**\n","    - **Total Exams Taken**\n","    - **Number of Exams with scores 3 4 or 5**\n","- Display the column types using the **dtypes** attribute."]},{"metadata":{"id":"_qW0QDiM8yFz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1969},"outputId":"61d9cbe0-133c-4fda-89cf-211c9b3ef4be","executionInfo":{"status":"ok","timestamp":1544475469116,"user_tz":120,"elapsed":690,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["# put your code here\n","\n","cols = [\"AP Test Takers \", \"Total Exams Taken\", \"Number of Exams with scores 3 4 or 5\"]\n","data['ap_2010'][cols].apply(pd.to_numeric, errors='coerce')\n","data['ap_2010']"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>DBN</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>Number of Exams with scores 3 4 or 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n","      <td>39</td>\n","      <td>49</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY HS</td>\n","      <td>19</td>\n","      <td>21</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>01M515</td>\n","      <td>LOWER EASTSIDE PREP</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>01M539</td>\n","      <td>NEW EXPLORATIONS SCI,TECH,MATH</td>\n","      <td>255</td>\n","      <td>377</td>\n","      <td>191</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>02M296</td>\n","      <td>High School of Hospitality Management</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>02M298</td>\n","      <td>Pace High School</td>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>02M300</td>\n","      <td>Urban Assembly School of Design and Construction,</td>\n","      <td>99</td>\n","      <td>117</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>02M303</td>\n","      <td>Facing History School, The</td>\n","      <td>42</td>\n","      <td>44</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>02M305</td>\n","      <td>Urban Assembly Academy of Government and Law, The</td>\n","      <td>25</td>\n","      <td>37</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>02M308</td>\n","      <td>Lower Manhattan Arts Academy</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>02M400</td>\n","      <td>HS FOR ENVIRONMENTAL STUDIES</td>\n","      <td>213</td>\n","      <td>298</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>02M408</td>\n","      <td>PROFESSIONAL PERFORMING ARTS</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>02M411</td>\n","      <td>BARUCH COLLEGE CAMPUS HS</td>\n","      <td>78</td>\n","      <td>115</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>02M412</td>\n","      <td>NYC LAB HS FOR COLL. STUDIES</td>\n","      <td>114</td>\n","      <td>140</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>02M413</td>\n","      <td>SCHOOL OF THE FUTURE</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>02M414</td>\n","      <td>NYC MUSEUM SCHOOL</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>02M416</td>\n","      <td>Eleanor Roosevelt High School</td>\n","      <td>155</td>\n","      <td>235</td>\n","      <td>169</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>02M418</td>\n","      <td>Millennium High School</td>\n","      <td>86</td>\n","      <td>95</td>\n","      <td>67</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>02M420</td>\n","      <td>HEALTH PROF &amp; HUMAN SVCS</td>\n","      <td>204</td>\n","      <td>248</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>02M425</td>\n","      <td>H S FOR LEADERSHIP &amp; PUBLIC</td>\n","      <td>70</td>\n","      <td>84</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>02M429</td>\n","      <td>LEGACY SCHOOL</td>\n","      <td>22</td>\n","      <td>26</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>02M439</td>\n","      <td>MANHATTAN VILLAGE ACADEMY HS</td>\n","      <td>42</td>\n","      <td>69</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>02M440</td>\n","      <td>HS FOR HUMANITIES</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>02M459</td>\n","      <td>CES-MANHATTAN INTERNATIONAL</td>\n","      <td>12</td>\n","      <td>12</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>02M460</td>\n","      <td>WASHINGTON IRVING HS</td>\n","      <td>69</td>\n","      <td>83</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>02M475</td>\n","      <td>STUYVESANT HS</td>\n","      <td>1510</td>\n","      <td>2819</td>\n","      <td>2648</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>02M489</td>\n","      <td>HS OF ECONOMICS &amp; FINANCE</td>\n","      <td>101</td>\n","      <td>176</td>\n","      <td>78</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>02M519</td>\n","      <td>TALENT UNLIMITED</td>\n","      <td>30</td>\n","      <td>34</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>28</td>\n","      <td>02M520</td>\n","      <td>MURRY BERGTRAUM H.S.</td>\n","      <td>118</td>\n","      <td>157</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>02M529</td>\n","      <td>JACQUELINE K. ONASSIS HS</td>\n","      <td>80</td>\n","      <td>118</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>228</td>\n","      <td>28Q620</td>\n","      <td>THOS A EDISON VHS</td>\n","      <td>183</td>\n","      <td>244</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>229</th>\n","      <td>229</td>\n","      <td>28Q680</td>\n","      <td>GATEWAY TO HEALTH SCIENCES</td>\n","      <td>89</td>\n","      <td>136</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>230</th>\n","      <td>230</td>\n","      <td>28Q687</td>\n","      <td>Queens HS for Science York Colllege</td>\n","      <td>215</td>\n","      <td>338</td>\n","      <td>275</td>\n","    </tr>\n","    <tr>\n","      <th>231</th>\n","      <td>231</td>\n","      <td>28Q690</td>\n","      <td>High School for Law Enforcement and Public Safety</td>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>232</th>\n","      <td>232</td>\n","      <td>28Q896</td>\n","      <td>Young  Women's Leadership School, Queens</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>233</td>\n","      <td>29Q248</td>\n","      <td>Queens Preparatory Academy</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>234</td>\n","      <td>29Q259</td>\n","      <td>Pathways College Preparatory School: A College...</td>\n","      <td>29</td>\n","      <td>71</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>235</td>\n","      <td>29Q272</td>\n","      <td>George Washington Carver High School for the S...</td>\n","      <td>14</td>\n","      <td>21</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>236</td>\n","      <td>29Q283</td>\n","      <td>Preparatory Academy for Writers</td>\n","      <td>40</td>\n","      <td>43</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>237</th>\n","      <td>237</td>\n","      <td>29Q420</td>\n","      <td>SPRINGFIELD GARDENS HS</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>238</td>\n","      <td>29Q492</td>\n","      <td>MATH/SCIENCE RESEARCH TECH CTR</td>\n","      <td>22</td>\n","      <td>31</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>239</td>\n","      <td>29Q496</td>\n","      <td>BUSINESS/COMPUTER APPLICATIONS</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>240</th>\n","      <td>240</td>\n","      <td>30Q445</td>\n","      <td>WM CULLEN BRYANT HS</td>\n","      <td>243</td>\n","      <td>330</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>241</th>\n","      <td>241</td>\n","      <td>30Q450</td>\n","      <td>LONG ISLAND CITY HS</td>\n","      <td>406</td>\n","      <td>805</td>\n","      <td>169</td>\n","    </tr>\n","    <tr>\n","      <th>242</th>\n","      <td>242</td>\n","      <td>30Q501</td>\n","      <td>FRANK SINATRA HIGH SCHOOL</td>\n","      <td>108</td>\n","      <td>136</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>243</th>\n","      <td>243</td>\n","      <td>30Q502</td>\n","      <td>INFORMATION TECHNOLOGY HS</td>\n","      <td>51</td>\n","      <td>74</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>244</th>\n","      <td>244</td>\n","      <td>30Q555</td>\n","      <td>NEWCOMERS HS:ACAD AMER STD</td>\n","      <td>119</td>\n","      <td>163</td>\n","      <td>140</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>245</td>\n","      <td>30Q575</td>\n","      <td>ACADEMY OF AMER. STUDIES HS</td>\n","      <td>101</td>\n","      <td>170</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>246</td>\n","      <td>31R080</td>\n","      <td>PS 080 MICHAEL J. PETRIDES</td>\n","      <td>162</td>\n","      <td>243</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>247</td>\n","      <td>31R440</td>\n","      <td>NEW DORP HS</td>\n","      <td>96</td>\n","      <td>118</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>248</td>\n","      <td>31R445</td>\n","      <td>PORT RICHMOND HS</td>\n","      <td>194</td>\n","      <td>304</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>249</th>\n","      <td>249</td>\n","      <td>31R450</td>\n","      <td>CURTIS HS</td>\n","      <td>247</td>\n","      <td>295</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>250</th>\n","      <td>250</td>\n","      <td>31R455</td>\n","      <td>TOTTENVILLE HS</td>\n","      <td>396</td>\n","      <td>687</td>\n","      <td>206</td>\n","    </tr>\n","    <tr>\n","      <th>251</th>\n","      <td>251</td>\n","      <td>31R460</td>\n","      <td>SUSAN E. WAGNER HS</td>\n","      <td>279</td>\n","      <td>408</td>\n","      <td>175</td>\n","    </tr>\n","    <tr>\n","      <th>252</th>\n","      <td>252</td>\n","      <td>31R600</td>\n","      <td>RAPLH MCKEE VHS</td>\n","      <td>s</td>\n","      <td>s</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>253</th>\n","      <td>253</td>\n","      <td>31R605</td>\n","      <td>STATEN ISLAND TECHNICAL HS</td>\n","      <td>528</td>\n","      <td>905</td>\n","      <td>809</td>\n","    </tr>\n","    <tr>\n","      <th>254</th>\n","      <td>254</td>\n","      <td>32K545</td>\n","      <td>EBC-HS FOR PUB SERVICE (BUSH)</td>\n","      <td>47</td>\n","      <td>64</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>255</th>\n","      <td>255</td>\n","      <td>32K552</td>\n","      <td>Academy of Urban Planning</td>\n","      <td>76</td>\n","      <td>100</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>256</th>\n","      <td>256</td>\n","      <td>32K554</td>\n","      <td>All City Leadership Secondary School</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>s</td>\n","    </tr>\n","    <tr>\n","      <th>257</th>\n","      <td>257</td>\n","      <td>32K556</td>\n","      <td>Bushwick Leaders High School for Academic Exce...</td>\n","      <td>34</td>\n","      <td>35</td>\n","      <td>18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>258 rows  6 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0     DBN                                         SchoolName  \\\n","0             0  01M448                       UNIVERSITY NEIGHBORHOOD H.S.   \n","1             1  01M450                             EAST SIDE COMMUNITY HS   \n","2             2  01M515                                LOWER EASTSIDE PREP   \n","3             3  01M539                     NEW EXPLORATIONS SCI,TECH,MATH   \n","4             4  02M296              High School of Hospitality Management   \n","5             5  02M298                                   Pace High School   \n","6             6  02M300  Urban Assembly School of Design and Construction,   \n","7             7  02M303                         Facing History School, The   \n","8             8  02M305  Urban Assembly Academy of Government and Law, The   \n","9             9  02M308                       Lower Manhattan Arts Academy   \n","10           10  02M400                       HS FOR ENVIRONMENTAL STUDIES   \n","11           11  02M408                       PROFESSIONAL PERFORMING ARTS   \n","12           12  02M411                           BARUCH COLLEGE CAMPUS HS   \n","13           13  02M412                       NYC LAB HS FOR COLL. STUDIES   \n","14           14  02M413                               SCHOOL OF THE FUTURE   \n","15           15  02M414                                  NYC MUSEUM SCHOOL   \n","16           16  02M416                      Eleanor Roosevelt High School   \n","17           17  02M418                             Millennium High School   \n","18           18  02M420                           HEALTH PROF & HUMAN SVCS   \n","19           19  02M425                        H S FOR LEADERSHIP & PUBLIC   \n","20           20  02M429                                      LEGACY SCHOOL   \n","21           21  02M439                       MANHATTAN VILLAGE ACADEMY HS   \n","22           22  02M440                                  HS FOR HUMANITIES   \n","23           23  02M459                        CES-MANHATTAN INTERNATIONAL   \n","24           24  02M460                               WASHINGTON IRVING HS   \n","25           25  02M475                                      STUYVESANT HS   \n","26           26  02M489                          HS OF ECONOMICS & FINANCE   \n","27           27  02M519                                   TALENT UNLIMITED   \n","28           28  02M520                               MURRY BERGTRAUM H.S.   \n","29           29  02M529                           JACQUELINE K. ONASSIS HS   \n","..          ...     ...                                                ...   \n","228         228  28Q620                                  THOS A EDISON VHS   \n","229         229  28Q680                         GATEWAY TO HEALTH SCIENCES   \n","230         230  28Q687                Queens HS for Science York Colllege   \n","231         231  28Q690  High School for Law Enforcement and Public Safety   \n","232         232  28Q896           Young  Women's Leadership School, Queens   \n","233         233  29Q248                         Queens Preparatory Academy   \n","234         234  29Q259  Pathways College Preparatory School: A College...   \n","235         235  29Q272  George Washington Carver High School for the S...   \n","236         236  29Q283                    Preparatory Academy for Writers   \n","237         237  29Q420                             SPRINGFIELD GARDENS HS   \n","238         238  29Q492                     MATH/SCIENCE RESEARCH TECH CTR   \n","239         239  29Q496                     BUSINESS/COMPUTER APPLICATIONS   \n","240         240  30Q445                                WM CULLEN BRYANT HS   \n","241         241  30Q450                                LONG ISLAND CITY HS   \n","242         242  30Q501                          FRANK SINATRA HIGH SCHOOL   \n","243         243  30Q502                          INFORMATION TECHNOLOGY HS   \n","244         244  30Q555                         NEWCOMERS HS:ACAD AMER STD   \n","245         245  30Q575                        ACADEMY OF AMER. STUDIES HS   \n","246         246  31R080                         PS 080 MICHAEL J. PETRIDES   \n","247         247  31R440                                        NEW DORP HS   \n","248         248  31R445                                   PORT RICHMOND HS   \n","249         249  31R450                                          CURTIS HS   \n","250         250  31R455                                     TOTTENVILLE HS   \n","251         251  31R460                                 SUSAN E. WAGNER HS   \n","252         252  31R600                                    RAPLH MCKEE VHS   \n","253         253  31R605                         STATEN ISLAND TECHNICAL HS   \n","254         254  32K545                      EBC-HS FOR PUB SERVICE (BUSH)   \n","255         255  32K552                          Academy of Urban Planning   \n","256         256  32K554               All City Leadership Secondary School   \n","257         257  32K556  Bushwick Leaders High School for Academic Exce...   \n","\n","    AP Test Takers  Total Exams Taken Number of Exams with scores 3 4 or 5  \n","0                39                49                                   10  \n","1                19                21                                    s  \n","2                24                26                                   24  \n","3               255               377                                  191  \n","4                 s                 s                                    s  \n","5                21                21                                    s  \n","6                99               117                                   10  \n","7                42                44                                    s  \n","8                25                37                                   15  \n","9                 s                 s                                    s  \n","10              213               298                                  152  \n","11               20                20                                   15  \n","12               78               115                                   88  \n","13              114               140                                   97  \n","14               11                11                                    s  \n","15                s                 s                                    s  \n","16              155               235                                  169  \n","17               86                95                                   67  \n","18              204               248                                   75  \n","19               70                84                                   32  \n","20               22                26                                    s  \n","21               42                69                                   29  \n","22                6                 6                                    s  \n","23               12                12                                    6  \n","24               69                83                                   21  \n","25             1510              2819                                 2648  \n","26              101               176                                   78  \n","27               30                34                                   21  \n","28              118               157                                   76  \n","29               80               118                                   29  \n","..              ...               ...                                  ...  \n","228             183               244                                  100  \n","229              89               136                                   57  \n","230             215               338                                  275  \n","231              19                19                                    s  \n","232               6                 6                                    s  \n","233              15                15                                    s  \n","234              29                71                                    s  \n","235              14                21                                    s  \n","236              40                43                                    s  \n","237               s                 s                                    s  \n","238              22                31                                    8  \n","239               s                 s                                    s  \n","240             243               330                                   97  \n","241             406               805                                  169  \n","242             108               136                                   38  \n","243              51                74                                   13  \n","244             119               163                                  140  \n","245             101               170                                  119  \n","246             162               243                                   66  \n","247              96               118                                   62  \n","248             194               304                                   76  \n","249             247               295                                   90  \n","250             396               687                                  206  \n","251             279               408                                  175  \n","252               s                 s                                    s  \n","253             528               905                                  809  \n","254              47                64                                   13  \n","255              76               100                                   10  \n","256               7                 8                                    s  \n","257              34                35                                   18  \n","\n","[258 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"8sB0lAzH8yF0","colab_type":"text"},"cell_type":"markdown","source":["## 1.11 Left, Right, Inner, and Outer Joins"]},{"metadata":{"id":"Vjm8aBE68yF1","colab_type":"text"},"cell_type":"markdown","source":["Before we merge our data, we'll need to decide on the merge strategy we want to use. We'll be using the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) function, which supports four types of joins -- **left**, **right**, **inner**, and **outer**. Each of these join types dictates how pandas combines the rows.\n","\n","We'll be using the **DBN** column to identify matching rows across data sets. In other words, the values in that column will help us know which row from the first data set to combine with which row in the second data set.\n","\n","There may be **DBN** values that exist in one data set but not in another. This is partly because the data is from different years. Each data set also has inconsistencies in terms of how it was gathered. Human error (and other types of errors) may also play a role. Therefore, we may not find matches for the **DBN** values in **sat_results** in all of the other data sets, and other data sets may have **DBN** values that don't exist in **sat_results**.\n","\n","We'll merge two data sets at a time. For example, we'll merge **sat_results** and **hs_directory**, then merge the result with **ap_2010**, then merge the result of that with **class_size**. We'll continue combining data sets in this way until we've merged all of them. Afterwards, we'll have roughly the same number of rows, but each row will have columns from all of the data sets.\n","\n","The merge strategy we pick will affect the number of rows we end up with. Let's take a look at each strategy.\n","\n","Let's say we're merging the following two data sets:\n","\n","<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Vlypix_SIkxCdRS0ABvO4tGiuvFLg321\"></left>\n","\n","With an **inner merge**, we'd only combine rows where the same **DBN** exists in both data sets. We'd end up with this result:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1LR4c8louX-JAZFYta_Y99FLsGkCf9grr\"></left>\n","\n","With a **left merge**, we'd only use **DBN** values from the dataframe on the \"left\" of the merge. In this case, **sat_results** is on the left. Some of the DBNs in **sat_results** don't exist in **class_size**, though. The merge will handle this by assiging null values to the columns in **sat_results** that don't have corresponding data in **class_size.**\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1hPoJ5wLECEzz25jrTP5bw9oZ0eerNi2p\"></left>\n","\n","With a **right merge**, we'll only use **DBN** values from the dataframe on the \"right\" of the merge. In this case, **class_size** is on the right:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1YYdf4iEMtHYqRBMTEFcfuTyu9zdFlnx7\"></left>\n","\n","With an outer merge, we'll take any DBN values from either sat_results or class_size:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1sl5wCK3WZ3lTzJm8JUn-bg4MoXl3xSe9\"></left>\n","\n","As you can see, each merge strategy has its advantages. Depending on the strategy we choose, we may preserve rows at the expense of having more missing column data, or minimize missing data at the expense of having fewer rows. Choosing a merge strategy is an important decision; it's worth thinking about your data carefully, and what trade-offs you're willing to make.\n","\n","Because this project is concerned with determing demographic factors that correlate with SAT score, we'll want to preserve as many rows as possible from **sat_results** while minimizing null values.\n","\n","This means that we may need to use different merge strategies with different data sets. Some of the data sets have a lot of missing **DBN** values. This makes a **left** join more appropriate, because we don't want to lose too many rows when we merge. If we did an **inner** join, we would lose the data for many high schools.\n","\n","Some data sets have **DBN** values that are almost identical to those in **sat_results**. Those data sets also have information we need to keep. Most of our analysis would be impossible if a significant number of rows was missing from **demographics**, for example. Therefore, we'll do an inner join to avoid missing data in these columns."]},{"metadata":{"id":"XpPfMAwI8yF1","colab_type":"text"},"cell_type":"markdown","source":["##  1.12 Performing the Left Joins"]},{"metadata":{"id":"TC5oEhTL8yF2","colab_type":"text"},"cell_type":"markdown","source":["Both the **ap_2010** and the **graduation** data sets have many missing **DBN** values, so we'll use a left join when we merge the **sat_results** data set with them. Because we're using a **left** join, our final dataframe will have all of the same **DBN** values as the original **sat_results** dataframe.\n","\n","We'll need to use the pandas **df.merge()** method to merge dataframes. The \"left\" dataframe is the one we call the method on, and the \"right\" dataframe is the one we pass into **df.merge()**.\n","\n","Because we're using the **DBN** column to join the dataframes, we'll need to specify the keyword argument **on=\"DBN\"** when calling **pandas.DataFrame.merge().**\n","\n","First, we'll assign **data[\"sat_results\"]** to the variable **combined**. Then, we'll merge all of the other dataframes with **combined**. When we're finished, **combined** will have all of the columns from all of the data sets.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Use the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) method to merge the **ap_2010** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to indicate the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Use the pandas **df.merge()** method to merge the **graduation** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to get the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Use the [pandas.DataFrame.shape](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.shape.html) attribute to display the shape of the dataframe and see how many rows now exist."]},{"metadata":{"id":"06arIDoX8yF3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bda5948a-1b12-4428-c1b7-2cbb2b746eac","executionInfo":{"status":"ok","timestamp":1544475475420,"user_tz":120,"elapsed":677,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["\n","combined = data['sat_results']\n","combined.head()\n","data['ap_2010'].head()\n","combined = combined.merge(data['ap_2010'], how='left', on='DBN')\n","combined = combined.merge(data['graduation'], how='left', on='DBN')\n","combined.head()\n","combined.shape\n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(479, 36)"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"VMMJAmet8yF6","colab_type":"text"},"cell_type":"markdown","source":["## 1.13 Performing the Inner Joins"]},{"metadata":{"id":"Nn8-wD4k8yF7","colab_type":"text"},"cell_type":"markdown","source":["Now that we've performed the left joins, we still have to merge **class_size**, **demographics**, **survey**, and **hs_directory** into **combined**. Because these files contain information that's more valuable to our analysis and also have fewer missing **DBN** values, we'll use the **inner** join type.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Merge **class_size** into **combined**. Then, merge **demographics**, **survey**, and **hs_directory** into **combined** one by one, in that order.\n","    - Be sure to follow the exact order above.\n","    - Remember to specify the correct column to join on, as well as the correct join type.\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Call **pandas.DataFrame.shape()** to display the shape of the dataframe to see how many rows now exist."]},{"metadata":{"id":"xEbfC4f58yF8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"486b2340-e141-4dfa-f3b1-025691444385","executionInfo":{"status":"ok","timestamp":1544475479976,"user_tz":120,"elapsed":713,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["# put your code here\n","combined = combined.merge(data['class_size'], how='left', on='DBN')\n","combined = combined.merge(data['demographics'], how='left', on='DBN')\n","combined = combined.merge(data['survey'], how='left', on='DBN')\n","combined = combined.merge(data['hs_directory'], how='left', on='DBN')\n","combined.head()\n","combined.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(479, 173)"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"LoZeRh6W8yF_","colab_type":"text"},"cell_type":"markdown","source":["##  1.14 Filling in Missing Values"]},{"metadata":{"id":"G_P59inq8yF_","colab_type":"text"},"cell_type":"markdown","source":["You may have noticed that the inner joins resulted in 116 fewer rows in **sat_results**. This is because pandas couldn't find the **DBN** values that existed in **sat_results** in the other data sets. While this is worth investigating, we're currently looking for high-level correlations, so we don't need to dive into which **DBNs** are missing.\n","\n","You may also have noticed that we now have many columns with null (**NaN**) values. This is because we chose to do **left** joins, where some columns may not have had data. The data set also had some missing values to begin with. If we hadn't performed a **left** join, all of the rows with missing data would have been lost in the merge process, which wouldn't have left us with many high schools in our data set.\n","\n","There are several ways to handle missing data, and we'll cover them in more detail later on. For now, we'll just fill in the missing values with the overall mean for the column, like so:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1OmhXzMuPrGSmyyugGXpmrRlLznDHxOeT\"></left>\n","\n","In the diagram above, the mean of the first column is (1800 + 1600 + 2200 + 2300) / 4, or 1975, and the mean of the second column is (20 + 30 + 30 + 50) / 4, or 32.5. We replace the missing values with the means of their respective columns, which allows us to proceed with analyses that can't handle missing values (like correlations).\n","\n","We can fill in missing data in pandas using the [pandas.DataFrame.fillna()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) method. This method will replace any missing values in a dataframe with the values we specify. We can compute the mean of every column using the [pandas.DataFrame.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html) method. If we pass the results of the **df.mean()** method into the **df.fillna()** method, pandas will fill in the missing values in each column with the mean of that column.\n","\n","Here's an example of how we would accomplish this:\n","\n","```python\n","means = df.mean()\n","df = df.fillna(means)\n","```\n","\n","Note that if a column consists entirely of null or **NaN** values, pandas won't be able to fill in the missing values when we use the **df.fillna()** method along with the **df.mean()** method, because there won't be a mean.\n","\n","We should fill any **NaN** or null values that remain after the initial replacement with the value 0. We can do this by passing 0 into the **df.fillna()** method.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Calculate the means of all of the columns in **combined** using the **pandas.DataFrame.mean()** method.\n","- Fill in any missing values in **combined** with the means of the respective columns using the **pandas.DataFrame.fillna()** method.\n","- Fill in any remaining missing values in **combined** with 0 using the **df.fillna()** method.\n","- Display the first few rows of **combined** to verify that the correct operations occurred."]},{"metadata":{"id":"XLJ8giWa8yGA","colab_type":"code","colab":{}},"cell_type":"code","source":["# put your code here\n","means = combined.mean()\n","combined = combined.fillna(means)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TkFLrp0r8yGG","colab_type":"text"},"cell_type":"markdown","source":["## 1.15 Adding a School District Column for Mapping"]},{"metadata":{"id":"Bhwo7emM8yGG","colab_type":"text"},"cell_type":"markdown","source":["We've finished cleaning and combining our data! We now have a clean data set on which we can base our analysis. Mapping the statistics out on a school district level might be an interesting way to analyze them. Adding a column to the data set that specifies the school district will help us accomplish this.\n","\n","The school district is just the first two characters of the **DBN**. We can apply a function over the **DBN** column of **combined** that pulls out the first two letters.\n","\n","For example, we can use indexing to extract the first few characters of a string, like this:\n","\n","```python\n","name = \"Sinbad\"\n","print(name[0:2])\n","```\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Write a function that extracts the first two characters of a string and returns them.\n","- Apply the function to the **DBN** column of **combined**, and assign the result to the **school_dist** column of **combined**.\n","- Display the first few items in the **school_dist** column of **combined** to verify the results.\n"]},{"metadata":{"id":"gIk75azA8yGG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"d506a703-1b7e-46a2-ec57-ca253016b57d","executionInfo":{"status":"ok","timestamp":1544475603271,"user_tz":120,"elapsed":737,"user":{"displayName":"Paulo Lopes","photoUrl":"https://lh3.googleusercontent.com/-4JSqBRxi3Gg/AAAAAAAAAAI/AAAAAAAAClk/7PktZC-Z2bs/s64/photo.jpg","userId":"08740800158508578487"}}},"cell_type":"code","source":["# put your code here\n","def extractor(data):\n","  return data[:2]\n","\n","combined['school_dist'] = combined['DBN'].apply(extractor)\n","combined['school_dist'].head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    01\n","1    01\n","2    01\n","3    01\n","4    01\n","Name: school_dist, dtype: object"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"q8407VxT8yGK","colab_type":"text"},"cell_type":"markdown","source":["## 1.16 Next Steps"]},{"metadata":{"id":"0YOOKVLg8yGK","colab_type":"text"},"cell_type":"markdown","source":["We now have a clean data set we can analyze! We've done a lot in this mission. We've gone from having several messy sources to one clean, combined, data set that's ready for analysis.\n","\n","Along the way, we've learned about:\n","\n","- How to handle missing values\n","- Different types of merges\n","- How to condense data sets\n","- How to compute averages across dataframes\n","\n","Data scientists rarely start out with tidy data sets, which makes cleaning and combining them one of the most critical skills any data professional can learn.\n"]}]}